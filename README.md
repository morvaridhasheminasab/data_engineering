
# DLMDSEDE02 - Phase 2 Submission

## ğŸ“Œ Project Title
**Quarterly Batch Processing Pipeline for Time-Series Stock Data**

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ data/              # Raw data files (CSV)
â”œâ”€â”€ delivery/          # FastAPI service to serve processed data
â”œâ”€â”€ documentation/     # Diagrams, NiFi template XML
â”œâ”€â”€ ingestion/         # Ingestion Docker/NiFi configurations
â”œâ”€â”€ processed/         # Output of NiFi processing
â”œâ”€â”€ storage/           # (Optional) Long-term file storage
â”œâ”€â”€ docker-compose.yml # Compose file for services
â”œâ”€â”€ README.md          # Project overview and usage
```

## ğŸ”§ How to Use

1. **Put your CSV data** in the `data/` folder (e.g. `prices_v2.csv`)
2. **Start services**:
```bash
docker-compose up --build
```
3. **Access Apache NiFi**:
   - URL: [http://localhost:8080/nifi](http://localhost:8080/nifi)
4. **Import your template** from `documentation/Phase2_Ingestion.xml`
   - Start the processors
5. **Processed data** will appear in the `processed/` folder
6. **Delivery service** (FastAPI) will be running at:
   - [http://localhost:8000](http://localhost:8000)

## âœ… Features

- NiFi-based batch ingestion pipeline
- Containerized delivery microservice (FastAPI)
- Configured with Docker Compose
- Handles 1M+ time-series entries
- Secure, maintainable, and scalable

## ğŸ§¾ Notes

- Tested locally with Docker Desktop (WSL2)
- Data must include a `date` column
- Developed for IUâ€™s DLMDSEDE02 course, Phase 2

---

ğŸ“ For full pipeline logic, see: `documentation/Phase2_Ingestion.xml`
## Phase 3 Summary

This repository now contains the final version of the batch-processing data architecture project, including:

- Fully functional Dockerized microservices
- Complete project documentation and reflection
- Data pipeline reproducible on any Docker-enabled system
- GitHub link document and architecture diagram

This project was submitted as part of the IU course DLMDSEDE02 (Data Engineering).

